{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Installs ###\n",
    "# %pip install langchain openai pypdf faiss-cpu python-dotenv tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Documentation\n",
    "\n",
    "__NEED AN OPENAI API KEY TO RUN__\n",
    "\n",
    "## Environment Setup\n",
    "- Load environment variables using `dotenv`.\n",
    "- Import necessary libraries like `os`, `glob`, and various modules from `langchain`.\n",
    "\n",
    "## Finding PDF Files\n",
    "- Function `find_pdf_files(directory)` lists all PDF files in a specified directory and subdirectories.\n",
    "- Uses `glob.glob` for searching and sorts the absolute paths of the PDF files.\n",
    "\n",
    "## Loading and Splitting Text\n",
    "- `load_and_split(path)` loads a PDF and splits its text into chunks.\n",
    "- Utilizes `PyPDFLoader` for reading PDF content.\n",
    "- `CharacterTextSplitter` breaks text into 1000 character chunks, separated by newline (`\\n`).\n",
    "\n",
    "## Setup PDF Files and Embeddings\n",
    "- Defines a list of file paths to various PDF documents.\n",
    "- Creates an embedding model using `OpenAIEmbeddings`.\n",
    "\n",
    "## Creating and Merging Vector Stores\n",
    "- For each PDF, the text is loaded, split, and converted into vector representations using `FAISS`.\n",
    "- Merges these vector stores into one primary store.\n",
    "\n",
    "## Saving and Loading Vector Store\n",
    "- Saves the merged vector store locally.\n",
    "- Reloads it using `FAISS.load_local`.\n",
    "\n",
    "## Demonstration with QA System\n",
    "- Sets up a QA system using `RetrievalQA` with an `OpenAI` language model and the loaded vector store.\n",
    "- Runs example queries to demonstrate information retrieval from the processed PDF documents.\n",
    "\n",
    "This setup establishes a document retrieval system using embeddings and a QA model, capable of answering questions based on content from the loaded PDF documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pdf_files(directory):\n",
    "    os.chdir(directory)\n",
    "\n",
    "    pdf_files = []\n",
    "\n",
    "    for file in glob.glob('**/*.pdf', recursive=True):\n",
    "        absolute_path = os.path.abspath(file)\n",
    "        pdf_files.append(absolute_path)\n",
    "        \n",
    "    pdf_files.sort()\n",
    "\n",
    "    return pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split(path):\n",
    "    loader = PyPDFLoader(file_path=path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # A chunk size of 1000 characters offers a balance between granularity and manageability\n",
    "    # It's large enough to contain meaningful units of text (like sentences or paragraphs),\n",
    "    # but small enough to be easily processed by various algorithms\n",
    "    # The absence of overlap means each character in the document is only processed once\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "            chunk_size=1000, chunk_overlap=0, separator=\"\\n\"\n",
    "        )\n",
    "    return text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/gray-city.pdf\",\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/irl.pdf\",\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/singing-peddler.pdf\",\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/memoirs.pdf\",\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/small-little-circle.pdf\",\n",
    "    \"/Users/aditkapoor/Local Documents/Work/Cognizant/langchain-proj/assets/data/veracious.pdf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstores = []\n",
    "\n",
    "for file_path in pdf_files:\n",
    "    docs = load_and_split(file_path)\n",
    "    \n",
    "    # I chose to use the FAISS vectorstore because it's the fastest to work with locally as I often\n",
    "    # needed to rebuild the vectorstore when I made changes to the code. With Pinecone, it was harder\n",
    "    # to make changes as I had to reset the vectorstore on the website instead of just deleting the locally\n",
    "    # saved stone (as FAISS manages it)\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    vectorstores.append(vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DEBUG CELL ###\n",
    "# vectorstores[0].docstore._dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(vectorstores)):\n",
    "    vectorstores[0].merge_from(vectorstores[i])\n",
    "    \n",
    "vectorstores[0].save_local(\"faiss_index_project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n",
    "new_vectorstore = FAISS.load_local(\"faiss_index_project\", embeddings)\n",
    "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type='stuff', retriever=new_vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Clyde's mom.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"Who did Clyde yet at about giving omniscient third person narrators too much information? If you don't know, say you don't know.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The father was sad after receiving the letter because it was the last letter he would ever receive from his son, who had been shot two weeks earlier.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"In the memoir, why was the father sad after receiving the letter?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The patches on people's clothing in the crowded streets of Delhi tell stories of poverty, of different fabrics from different times, of hand-me-downs, and of people striving to cover up patches that are all too visible. They reflect the diversity and history of the city, of a place full of people with different backgrounds and experiences.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"In the crowded streets of Delhi, what stories do the patches on people's clothing tell, as described in the poem? Reflect on the diversity and history embedded in these patches.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IRL portrays the world post-internet and modern relationships as interconnected and interdependent. The author describes how two people were connected through the internet and were finally able to meet in person. The internet has connected people in ways which would have been impossible before, allowing them to form relationships which transcend physical barriers.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"How does \\\"IRL\\\" portray the world post-internet and modern relationships?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In \"Veracious\", the author is mad at his Uncle Scott for leaving his family behind in such a difficult time. The author feels especially hurt as his Uncle had been doing better and making plans for the future, like getting a job and moving out of his family home. The author had looked up to his Uncle as a child, and was disappointed that he had left them all so suddenly. The author felt that his Uncle was selfish for not being able to wait, even in death, and for reducing his mother to a vulnerable state. The author was also angry that his Uncle had left his grandmother, JoJo, all alone in her house with no one to take care of her.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"In \\\"Veracious\\\", why is the author so mad at his Uncle despite his untimely death? Give me around 5 sentences.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The author felt a strong connection with Maggi. He found comfort in her presence and in the way she interacted with him. He was able to confide in her and talk to her as if she was an understanding person. He felt like he could share his feelings and emotions with her without judgement, and this made him feel less alone.\n"
     ]
    }
   ],
   "source": [
    "result = qa.run(\"Describe the Author's relationship with Maggi. Why was he so attached to her?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"  # Fill in with your own prompt\n",
    "result = qa.run(prompt)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
